---
title: "Summer 2024 SEC Information Retrieval [FSIL] -- Annotating Round 1"
format: html
---

# 0. List of labels

## Deal Type: [Deal Type, Deal Sub-Type]

There are many entities in the financial contracts. For example, the **role** of an organization in the credit contract is not limited to borrower and lender. A fine grained understanding of the entities is required for any financial analysis.

Here are the some of the entities + roles that we need to annotate for the NER model. Note the roles and entities are not exhaustive, but merely illustrative.

1. revolver: revolver - 364 day, revolver.
2. term loan - term loan A, term loan B, term loan C, term loan D etc.,
3. Line of credits. 

# 1. Annotating

You will work in your personal project in Label Studio named as your email address (see important note 2). Initially, there is only one label in your project -- 'boilerplate'. You may or may not use it for annotating the parts of documents which do not contain any unique useful information. What you need to do is add all of the above labels. To do that, open your project -> Settings -> Labeling Interface. Add the labels using the corresponding textbox and button.

Here are the [instructions](https://labelstud.io/guide/labeling.html) on annotating in Label Studio (in case you have issues and have not seen them).

 - 1.1. First, select one of the credit agreements and annotate it with one of the given labels. While doing this, analyze the document's structure and consider which information is presented in each section (as you were asked to do with the example project). Pay attention to the information that should be highlighted with the other labels, but focus primarily on the chosen label.

 - 1.2. While labeling, you will likely encounter different linguistic forms of the same entities, such as abbreviations and plural forms. This is a good opportunity to start working on your annotation guide (see step 2).

 - 1.3. For the other labels, think about the forms they might take and where they might appear. Annotate the document accordingly and work on your annotation guide in parallel.

 - 1.4. Annotate the rest of the documents with the all given labels and make changes to the annotation guide if needed.
 
 - 1.5. As mentioned above, the list of labels is not exhaustive. You may and should think of other labels similar to yours that could be used for annotating. If you come up with new labels you consider useful, describe your reasoning in the annotation guide. Do not use them for annotating the documents yet.

# 2. Writing an Annotation Guide

Review the annotation guides in the FiNER and Trillion Dollar Words papers and think about how you want to annotate the given documents. **We also highly recommend looking at the [CUAD](https://www.atticusprojectai.org/cuad) dataset (especially the README and datasheet) published in NeurIPS.** These are examples of best practices of annotating and documenting.

# 3. Create a comprehensive document (pdf)

The final document you submit to us should include:

 - Annotation guideline with examples;
 - Edge cases with examples;
 - Any questions you may have;
 - New labels you think we should add to cover the task at hand well.

Please, do not email us your questions right now unless they prevent you from moving on. When you finish annotating, writing the guideline and the document, reply to the email containing this file with your document attached. We will schedule a 1-1 meeting with you once we look at your document.

# Important Notes

 - 1. **Do not use LLMs to annotate the documents for you.** Firstly, LLMs are much less effective at annotation than it might seem, and this will be evident if you use them. Secondly, the annotation process itself is very beneficial for you, as we have mentioned before. It is a vital, inevitable part of any large project. If your annotations are suspected to be generated by an LLM, it may result in your dismissal. You are, however, allowed to use Ctrl+F if it helps you, but keep in mind the linguistic variations.

 - 2. **Do not look at each otherâ€™s projects.** This will result in significant bias in the annotations. Despite Label Studio does not allow to restrict the opportunity to visit all the projects, it prodides us as admins with seeing everyone's activiy. Visiting the projects of others may result in your dismissal.
 
